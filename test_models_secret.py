import pytest
import time
import numpy as np
import torch
import torch.nn.functional as F
import secretflow as sf
import spu  # <--- [FIX 1] å¿…é¡»å¯¼å…¥ spu åŒ…

# å¯¼å…¥ä½ çš„æ¨¡åž‹
from models_secret import UnifiedSecretHadamardRetriever
from models_plain import UnifiedLSHRetriever
from data_loader import GISTDataLoader

# ==========================================
# 1. è¾…åŠ©å·¥å…·: çœŸå€¼è®¡ç®—ä¸Žä½æ‰“åŒ…
# ==========================================
def compute_ground_truth(db, qs, k=100):
    """æš´åŠ›è®¡ç®— Top-K çœŸå€¼ (åŸºäºŽ Cosine ç›¸ä¼¼åº¦)"""
    print(f"âš¡ Computing Ground Truth for {len(qs)} queries...")
    # å‡è®¾æ•°æ®å·²å½’ä¸€åŒ–ï¼Œä½¿ç”¨çŸ©é˜µä¹˜æ³•è®¡ç®— Cosine
    scores = torch.mm(qs, db.t())
    _, indices = torch.topk(scores, k=k, largest=True)
    return indices

def pack_secret_output(fp_01_np, plain_model):
    """
    å°† SPU è¾“å‡ºçš„æœªåŽ‹ç¼© 0/1 æŒ‡çº¹æ‰“åŒ…æˆ int64 æ ¼å¼ï¼Œ
    ä»¥ä¾¿ç›´æŽ¥è°ƒç”¨ plain_model.query_with_fingerprints
    """
    # fp_01_np shape: (Batch, Tables, Bits)
    device = plain_model.device
    fp_tensor = torch.tensor(fp_01_np, dtype=torch.int64, device=device)
    
    packed_fp = []
    bits_per_table = fp_tensor.shape[-1]
    
    # æŒ‰ 64 ä½åˆ†å—æ‰“åŒ…
    for i in range(0, bits_per_table, 64):
        chunk = fp_tensor[:, :, i:i + 64]
        # å¦‚æžœä¸è¶³ 64 ä½ï¼Œè¿›è¡Œ Padding
        if chunk.shape[2] < 64: 
            chunk = F.pad(chunk, (0, 64 - chunk.shape[2]))
        
        # è°ƒç”¨ plain_model çš„åº•å±‚æ‰“åŒ…å‡½æ•°
        # è¾“å‡º shape: (Batch, Tables)
        packed_chunk = plain_model._pack_bits(chunk)
        packed_fp.append(packed_chunk.unsqueeze(-1))
    
    # æ‹¼æŽ¥ chunks: (Batch, Tables, Num_Chunks)
    return torch.cat(packed_fp, dim=-1)

# ==========================================
# 2. æµ‹è¯•çŽ¯å¢ƒ (å·²ä¿®æ­£)
# ==========================================
@pytest.fixture(scope="module")
def sf_setup():
    sf.shutdown()
    sf.init(['alice', 'bob'], address='local')
    alice = sf.PYU('alice')
    bob = sf.PYU('bob')
    
    # [FIX 2] ä½¿ç”¨ spu.ProtocolKind è€Œéž sf.utils.testing.spu_pb2
    cluster_def = sf.utils.testing.cluster_def(
        ['alice', 'bob'],
        runtime_config={
            'protocol': spu.ProtocolKind.SEMI2K,
            'field': spu.FieldType.FM64,
            'enable_pphlo_profile': False
        }
    )
    # æ³¨æ„è¿™é‡Œå˜é‡åæ”¹ä¸º spu_device é˜²æ­¢ä¸Ž import spu å†²çª
    spu_device = sf.SPU(cluster_def)
    
    yield alice, bob, spu_device
    
    sf.shutdown()

class TestAccuracyAndPerformance:
    
    @pytest.fixture(scope="class")
    def dataset(self):
        """åŠ è½½æ•°æ®å¹¶è®¡ç®—çœŸå€¼"""
        DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
        loader = GISTDataLoader()
        # åŠ è½½è¾ƒå¤šæ•°æ®ä»¥ä¿è¯ Recall è®¡ç®—çš„ç»Ÿè®¡æ„ä¹‰
        db, qs = loader.load_data(device=DEVICE, train_limit=10000, test_limit=100)
        
        # è®¡ç®—çœŸå€¼ (Top-100)
        gt_indices = compute_ground_truth(db, qs, k=100)
        
        return {
            "db": db, 
            "qs": qs, 
            "gt": gt_indices,
            "device": DEVICE
        }

    @pytest.fixture(scope="class")
    def model_configs(self):
        return [
            # 1. ç”Ÿäº§çº§ (FWHT + PublicPerm) - é¢„æœŸ: é«˜Recall, é«˜QPS
            {
                "name": "ðŸš€ PublicPerm (Prod)",
                "fwht": True, 
                "public_perm": True,
                "tables": 4
            },
            # 2. æ¶ˆèžå®žéªŒ (No FWHT) - é¢„æœŸ: ä½ŽRecall, é«˜QPS
            {
                "name": "ðŸ§ª No-FWHT (Ablation)",
                "fwht": False, 
                "public_perm": True,
                "tables": 4
            },
            # 3. å…¨éšç§ (SecretPerm) - é¢„æœŸ: é«˜Recall, æžä½ŽQPS
            # æ³¨æ„ï¼šè¿™ä¸ªè·‘èµ·æ¥å¾ˆæ…¢ï¼Œä»…ç”¨äºŽéªŒè¯æ­£ç¡®æ€§
            {
                "name": "ðŸ”’ SecretPerm (Basic)",
                "fwht": True, 
                "public_perm": False,
                "tables": 4
            }
        ]

    def test_recall_and_perf(self, sf_setup, dataset, model_configs):
        # æ³¨æ„è¿™é‡Œè§£åŒ…å˜é‡åè¦å¯¹åº” fixture çš„ yield
        alice, bob, spu_device = sf_setup
        db, qs, gt_indices = dataset['db'], dataset['qs'], dataset['gt']
        device = dataset['device']
        
        BITS = 2048
        TOP_K = 100
        
        print("\n" + "="*110)
        print(f"ðŸ“Š FULL BENCHMARK: Recall@{TOP_K} & QPS")
        print("="*110)
        print(f"{'Model Name':<25} | {'Recall':<8} | {'Latency(s)':<10} | {'QPS':<8} | {'Build(s)':<8}")
        print("-" * 110)
        
        for cfg in model_configs:
            # 1. å‡†å¤‡æ˜Žæ–‡æ¨¡åž‹ (ä½œä¸ºå‚æ•°æºå’Œæœç´¢å¼•æ“Ž)
            plain_model = UnifiedLSHRetriever(
                input_dim=960, 
                total_bits=BITS, 
                num_tables=cfg['tables'], 
                projection_type='hadamard',
                device=device
            )
            # è®­ç»ƒæ˜Žæ–‡æ¨¡åž‹ (æž„å»º DB ç´¢å¼•)
            plain_model.train(db)
            
            # 2. å®žä¾‹åŒ–ç§˜å¯†æ¨¡åž‹
            secret_model = UnifiedSecretHadamardRetriever(
                spu_device, plain_model, alice, bob,
                num_tables=cfg['tables'],
                use_fwht=cfg['fwht'],
                use_public_perm=cfg['public_perm']
            )
            
            # 3. Build é˜¶æ®µè®¡æ—¶
            t_build = secret_model.build_secret()
            
            # 4. Query é˜¶æ®µ (æ€§èƒ½ + å¬å›ž)
            qs_np = qs.cpu().numpy()
            
            try:
                # åªæœ‰ SecretPerm æ¨¡å¼ä¸‹ï¼Œä¸ºäº†é˜²è¶…æ—¶ï¼Œæˆ‘ä»¬åªæµ‹å°‘é‡æ•°æ®
                if not cfg['public_perm']:
                    qs_subset = qs_np[:5] # è¿›ä¸€æ­¥å‡å°ä»¥é˜²è¶…æ—¶
                    gt_subset = gt_indices[:5]
                    bs = 5
                else:
                    qs_subset = qs_np
                    gt_subset = gt_indices
                    bs = len(qs_np)

                # --- æ ¸å¿ƒè®¡æ—¶ ---
                fp_01, t_query = secret_model.query_secret(qs_subset)
                # ----------------
                
                # 5. åŽå¤„ç†: è®¡ç®— Recall
                # a. æ‰“åŒ…æŒ‡çº¹ (0/1 -> int64)
                q_fp_packed = pack_secret_output(fp_01, plain_model)
                
                # b. åœ¨æ˜Žæ–‡åº“ä¸­æ£€ç´¢
                _, pred_indices = plain_model.query_with_fingerprints(q_fp_packed, k=TOP_K)
                
                # c. è®¡ç®—äº¤é›† (Recall)
                hits = 0
                for i in range(bs):
                    gt_set = set(gt_subset[i].tolist())
                    pred_set = set(pred_indices[i].tolist())
                    hits += len(gt_set & pred_set)
                
                recall = hits / (bs * TOP_K)
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                latency = t_query / bs
                qps = bs / t_query
                
                print(f"{cfg['name']:<25} | {recall:.2%}   | {latency:.4f}     | {qps:.2f}     | {t_build:.4f}")

            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"{cfg['name']:<25} | ERROR: {str(e)[:30]}...")

    print("-" * 110)