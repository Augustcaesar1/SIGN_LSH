import pytest
import time
import numpy as np
import torch
import torch.nn.functional as F
import secretflow as sf
import spu
import pandas as pd  # ç”¨äºŽæ¼‚äº®çš„è¡¨æ ¼è¾“å‡º

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from models_secret import UnifiedSecretHadamardRetriever
from models_plain import UnifiedLSHRetriever
from data_loader import GISTDataLoader

# ==========================================
# 0. åŸºç¡€å·¥å…·å‡½æ•°
# ==========================================
def compute_ground_truth(db, qs, k=100):
    print(f"âš¡ [Prep] Computing Ground Truth for {len(qs)} queries...")
    scores = torch.mm(qs, db.t())
    _, indices = torch.topk(scores, k=k, largest=True)
    return indices

def pack_secret_output(fp_01_np, plain_model):
    """0/1 çŸ©é˜µæ‰“åŒ…ä¸º int64"""
    device = plain_model.device
    fp_tensor = torch.tensor(fp_01_np, dtype=torch.int64, device=device)
    packed_fp = []
    bits_per_table = fp_tensor.shape[-1]
    for i in range(0, bits_per_table, 64):
        chunk = fp_tensor[:, :, i:i + 64]
        if chunk.shape[2] < 64: chunk = F.pad(chunk, (0, 64 - chunk.shape[2]))
        packed_chunk = plain_model._pack_bits(chunk)
        packed_fp.append(packed_chunk.unsqueeze(-1))
    return torch.cat(packed_fp, dim=-1)

# ==========================================
# 1. æ ¸å¿ƒæµ‹è¯•é€»è¾‘
# ==========================================
class ParameterImpactBenchmark:
    
    def setup_env(self):
        sf.shutdown()
        sf.init(['alice', 'bob'], address='local')
        # SPU é…ç½®
        cluster_def = sf.utils.testing.cluster_def(
            ['alice', 'bob'],
            runtime_config={
                'protocol': spu.ProtocolKind.SEMI2K,
                'field': spu.FieldType.FM64,
                'enable_pphlo_profile': False
            }
        )
        self.alice = sf.PYU('alice')
        self.bob = sf.PYU('bob')
        self.spu = sf.SPU(cluster_def)
        
        # æ•°æ®åŠ è½½
        DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
        loader = GISTDataLoader()
        self.db, self.qs = loader.load_data(device=DEVICE, train_limit=10000, test_limit=100)
        self.gt_indices = compute_ground_truth(self.db, self.qs, k=100)
        self.device = DEVICE
        
        # é¢„è®­ç»ƒä¸€ä¸ªè¶³å¤Ÿå¤§çš„æ˜Žæ–‡æ¨¡åž‹ (Tables=8) ä¾›åŽç»­è£å‰ªä½¿ç”¨
        print("âš¡ [Prep] Training Base Plain Model (Tables=8)...")
        self.base_plain_model = UnifiedLSHRetriever(
            input_dim=960, total_bits=2048, num_tables=8, 
            projection_type='hadamard', device=DEVICE
        )
        self.base_plain_model.train(self.db)

    def run_single_experiment(self, name, tables, fwht, public_perm):
        """è¿è¡Œå•ä¸ªå®žéªŒé…ç½®å¹¶è¿”å›žæŒ‡æ ‡"""
        print(f"\nðŸ§ª Running Exp: [{name}]")
        print(f"   Configs: Tables={tables}, FWHT={fwht}, PublicPerm={public_perm}")
        
        # å®žä¾‹åŒ–ç§˜å¯†æ¨¡åž‹
        secret_model = UnifiedSecretHadamardRetriever(
            self.spu, self.base_plain_model, self.alice, self.bob,
            num_tables=tables, use_fwht=fwht, use_public_perm=public_perm
        )
        
        # 1. Build
        t_build = secret_model.build_secret()
        
        # 2. Query (æ™ºèƒ½ Batch)
        # å¦‚æžœæ˜¯å…¨éšç§æ¨¡å¼(PublicPerm=False)ï¼Œåªæµ‹ 1 æ¡æ•°æ®ä¼°ç®—æ€§èƒ½ï¼Œé¿å…å¡æ­»
        qs_np = self.qs.cpu().numpy()
        if not public_perm:
            qs_subset = qs_np[:1]
            gt_subset = self.gt_indices[:1]
            bs = 1
            print("   âš ï¸  [Slow Mode] Detected SecretPerm, reducing batch size to 1...")
        else:
            qs_subset = qs_np
            gt_subset = self.gt_indices
            bs = len(qs_np)
            
        try:
            fp_01, t_query = secret_model.query_secret(qs_subset)
            
            # 3. Recall è®¡ç®—
            q_fp_packed = pack_secret_output(fp_01, self.base_plain_model)
            _, pred_indices = self.base_plain_model.query_with_fingerprints(q_fp_packed, k=100)
            
            hits = 0
            for i in range(bs):
                hits += len(set(gt_subset[i].tolist()) & set(pred_indices[i].tolist()))
            
            recall = hits / (bs * 100)
            latency = t_query / bs
            qps = bs / t_query
            
            return {
                "Scenario": name,
                "Tables": tables,
                "FWHT": fwht,
                "PublicPerm": public_perm,
                "Recall@100": f"{recall:.2%}",
                "Latency(s)": f"{latency:.4f}",
                "QPS": f"{qps:.2f}",
                "Consequence": "" # ç¨åŽå¡«å……
            }
        except Exception as e:
            return {"Scenario": name, "Error": str(e)[:30]}

    def run_all(self):
        self.setup_env()
        results = []
        
        # ==========================================
        # å®žéªŒç»„ 1: æ•°å­¦çš„åŽæžœ (FWHT çš„é‡è¦æ€§)
        # æŽ§åˆ¶å˜é‡: Tables=4, PublicPerm=True
        # ==========================================
        print("\n=== Experiment 1: The Consequence of Math (FWHT) ===")
        res_no_fwht = self.run_single_experiment("No FWHT", tables=4, fwht=False, public_perm=True)
        res_no_fwht['Consequence'] = "âŒ å¬å›žçŽ‡å´©å¡Œ (æ•°å­¦å¤±æ•ˆ)"
        results.append(res_no_fwht)
        
        res_fwht = self.run_single_experiment("With FWHT", tables=4, fwht=True, public_perm=True)
        res_fwht['Consequence'] = "âœ… é«˜å¬å›ž (æ•°å­¦æœ‰æ•ˆ)"
        results.append(res_fwht)
        
        # ==========================================
        # å®žéªŒç»„ 2: éšç§çš„ä»£ä»· (PublicPerm çš„é‡è¦æ€§)
        # æŽ§åˆ¶å˜é‡: Tables=4, FWHT=True
        # ==========================================
        print("\n=== Experiment 2: The Consequence of Privacy (Permutation) ===")
        # æˆ‘ä»¬å¤ç”¨ä¸Šé¢çš„ res_fwht ä½œä¸ºå¯¹ç…§ç»„
        
        res_secret_perm = self.run_single_experiment("Secret Perm", tables=4, fwht=True, public_perm=False)
        res_secret_perm['Consequence'] = "âŒ é€Ÿåº¦æ…¢ 100+ å€ (OAM ä»£ä»·)"
        results.append(res_secret_perm)
        
        # ==========================================
        # å®žéªŒç»„ 3: è§„æ¨¡çš„æƒè¡¡ (NumTables çš„é‡è¦æ€§)
        # æŽ§åˆ¶å˜é‡: FWHT=True, PublicPerm=True
        # ==========================================
        print("\n=== Experiment 3: The Trade-off of Scale (Num Tables) ===")
        
        res_t1 = self.run_single_experiment("Tables=1", tables=1, fwht=True, public_perm=True)
        res_t1['Consequence'] = "ðŸ“‰ å¬å›žä½Žï¼Œé€Ÿåº¦æžå¿«"
        results.append(res_t1)
        
        # Tables=4 å·²ç»è·‘è¿‡äº† (res_fwht)
        
        res_t8 = self.run_single_experiment("Tables=8", tables=8, fwht=True, public_perm=True)
        res_t8['Consequence'] = "ðŸ“ˆ å¬å›žé«˜ï¼Œå­˜å‚¨/è®¡ç®—ç¿»å€"
        results.append(res_t8)
        
        # ==========================================
        # æœ€ç»ˆæŠ¥å‘Š
        # ==========================================
        df = pd.DataFrame(results)
        # è°ƒæ•´åˆ—é¡ºåº
        cols = ["Scenario", "Tables", "FWHT", "PublicPerm", "Recall@100", "Latency(s)", "QPS", "Consequence"]
        print("\n" + "="*100)
        print("ðŸ“Š FINAL PARAMETER IMPACT REPORT")
        print("="*100)
        print(df[cols].to_string(index=False))
        print("="*100)

if __name__ == "__main__":
    benchmark = ParameterImpactBenchmark()
    benchmark.run_all()