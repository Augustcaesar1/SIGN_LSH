import pytest
import time
import numpy as np
import torch
import torch.nn.functional as F
import secretflow as sf
import spu  # <--- [FIX 1] å¿…é¡»å¯¼å…¥ spu åŒ…

# å¯¼å…¥ä½ çš„æ¨¡åž‹
from models_secret import UnifiedSecretHadamardRetriever
from models_plain import UnifiedLSHRetriever
from data_loader import GISTDataLoader

# ==========================================
# 1. è¾…åŠ©å·¥å…·: çœŸå€¼è®¡ç®—ä¸Žä½æ‰“åŒ…
# ==========================================
def compute_ground_truth(db, qs, k=100):
    """æš´åŠ›è®¡ç®— Top-K çœŸå€¼ (åŸºäºŽ Cosine ç›¸ä¼¼åº¦)"""
    print(f"âš¡ Computing Ground Truth for {len(qs)} queries...")
    # å‡è®¾æ•°æ®å·²å½’ä¸€åŒ–ï¼Œä½¿ç”¨çŸ©é˜µä¹˜æ³•è®¡ç®— Cosine
    scores = torch.mm(qs, db.t())
    _, indices = torch.topk(scores, k=k, largest=True)
    return indices

def pack_secret_output(fp_01_np, plain_model):
    """
    å°† SPU è¾“å‡ºçš„æœªåŽ‹ç¼© 0/1 æŒ‡çº¹æ‰“åŒ…æˆ int64 æ ¼å¼
    """
    device = plain_model.device
    fp_tensor = torch.tensor(fp_01_np, dtype=torch.int64, device=device)
    
    packed_fp = []
    bits_per_table = fp_tensor.shape[-1]
    
    # æŒ‰ 64 ä½åˆ†å—æ‰“åŒ…
    for i in range(0, bits_per_table, 64):
        chunk = fp_tensor[:, :, i:i + 64]
        if chunk.shape[2] < 64: 
            chunk = F.pad(chunk, (0, 64 - chunk.shape[2]))
        
        packed_chunk = plain_model._pack_bits(chunk)
        packed_fp.append(packed_chunk.unsqueeze(-1))
    
    return torch.cat(packed_fp, dim=-1)

# ==========================================
# 2. æµ‹è¯•çŽ¯å¢ƒ (å·²ä¿®æ­£)
# ==========================================
class TestAccuracyAndPerformance:

    @pytest.fixture(scope="class")
    def sf_setup(self):
        """åˆå§‹åŒ– SecretFlow çŽ¯å¢ƒ"""
        # 1. æ¸…ç†æ—§çŽ¯å¢ƒ
        sf.shutdown()
        
        # 2. åˆå§‹åŒ– (Standalone æ¨¡å¼)
        sf.init(['alice', 'bob'], address='local')
        alice = sf.PYU('alice')
        bob = sf.PYU('bob')
        
        # [æ ¸å¿ƒä¿®å¤ 2] ä½¿ç”¨ spu.ProtocolKind è€Œéž sf.utils.testing.spu_pb2
        cluster_def = sf.utils.testing.cluster_def(
            ['alice', 'bob'],
            runtime_config={
                'protocol': spu.ProtocolKind.SEMI2K,  # <--- [FIXED] è¿™é‡Œå¿…é¡»ç”¨ spu.ProtocolKind
                'field': spu.FieldType.FM64,          # <--- [FIXED] è¿™é‡Œå¿…é¡»ç”¨ spu.FieldType
                'enable_pphlo_profile': False
            }
        )
        spu_device = sf.SPU(cluster_def)
        
        yield alice, bob, spu_device
        
        sf.shutdown()

    @pytest.fixture(scope="class")
    def dataset(self):
        """åŠ è½½æ•°æ®å¹¶è®¡ç®—çœŸå€¼"""
        DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
        loader = GISTDataLoader()
        # åŠ è½½è¾ƒå¤šæ•°æ®ä»¥ä¿è¯ Recall è®¡ç®—çš„ç»Ÿè®¡æ„ä¹‰
        db, qs = loader.load_data(device=DEVICE, train_limit=10000, test_limit=100)
        
        # è®¡ç®—çœŸå€¼ (Top-100)
        gt_indices = compute_ground_truth(db, qs, k=100)
        
        return {
            "db": db, 
            "qs": qs, 
            "gt": gt_indices,
            "device": DEVICE
        }

    @pytest.fixture(scope="class")
    def model_configs(self):
        return [
            # 1. ç”Ÿäº§çº§ (FWHT + PublicPerm)
            {
                "name": "ðŸš€ PublicPerm (Prod)",
                "fwht": True, 
                "public_perm": True,
                "tables": 4
            },
            # 2. æ¶ˆèžå®žéªŒ (No FWHT)
            {
                "name": "ðŸ§ª No-FWHT (Ablation)",
                "fwht": False, 
                "public_perm": True,
                "tables": 4
            },
            # 3. å…¨éšç§ (SecretPerm)
            {
                "name": "ðŸ”’ SecretPerm (Basic)",
                "fwht": True, 
                "public_perm": False,
                "tables": 4
            }
        ]

    def test_recall_and_perf(self, sf_setup, dataset, model_configs):
        alice, bob, spu_device = sf_setup
        db, qs, gt_indices = dataset['db'], dataset['qs'], dataset['gt']
        device = dataset['device']
        
        BITS = 2048
        TOP_K = 100
        
        print("\n" + "="*110)
        print(f"ðŸ“Š FULL BENCHMARK: Recall@{TOP_K} & QPS")
        print("="*110)
        print(f"{'Model Name':<25} | {'Recall':<8} | {'Latency(s)':<10} | {'QPS':<8} | {'Build(s)':<8}")
        print("-" * 110)
        
        for cfg in model_configs:
            # 1. å‡†å¤‡æ˜Žæ–‡æ¨¡åž‹
            plain_model = UnifiedLSHRetriever(
                input_dim=960, 
                total_bits=BITS, 
                num_tables=cfg['tables'], 
                projection_type='hadamard',
                device=device
            )
            plain_model.train(db)
            
            # 2. å®žä¾‹åŒ–ç§˜å¯†æ¨¡åž‹
            secret_model = UnifiedSecretHadamardRetriever(
                spu_device, plain_model, alice, bob,
                num_tables=cfg['tables'],
                use_fwht=cfg['fwht'],
                use_public_perm=cfg['public_perm']
            )
            
            # 3. Build è®¡æ—¶
            t_build = secret_model.build_secret()
            
            # 4. Query & Recall
            qs_np = qs.cpu().numpy()
            
            try:
                # SecretPerm æ¨¡å¼ä¸‹åªæµ‹å°‘é‡æ•°æ®é˜²è¶…æ—¶
                if not cfg['public_perm']:
                    qs_subset = qs_np[:5]
                    gt_subset = gt_indices[:5]
                    bs = 5
                else:
                    qs_subset = qs_np
                    gt_subset = gt_indices
                    bs = len(qs_np)

                # --- æ ¸å¿ƒè®¡æ—¶ ---
                fp_01, t_query = secret_model.query_secret(qs_subset)
                # ----------------
                
                # è®¡ç®— Recall
                q_fp_packed = pack_secret_output(fp_01, plain_model)
                _, pred_indices = plain_model.query_with_fingerprints(q_fp_packed, k=TOP_K)
                
                hits = 0
                for i in range(bs):
                    gt_set = set(gt_subset[i].tolist())
                    pred_set = set(pred_indices[i].tolist())
                    hits += len(gt_set & pred_set)
                
                recall = hits / (bs * TOP_K)
                latency = t_query / bs
                qps = bs / t_query
                
                print(f"{cfg['name']:<25} | {recall:.2%}   | {latency:.4f}     | {qps:.2f}     | {t_build:.4f}")

            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"{cfg['name']:<25} | ERROR: {str(e)[:30]}...")

    print("-" * 110)

if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s", "--tb=short"])