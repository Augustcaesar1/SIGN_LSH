import pytest
import time
import numpy as np
import torch
import torch.nn.functional as F
import secretflow as sf

# å¯¼å…¥ä½ çš„æ¨¡å‹
from models_secret import UnifiedSecretHadamardRetriever
from models_plain import UnifiedLSHRetriever
from data_loader import GISTDataLoader

# ==========================================
# 1. è¾…åŠ©å·¥å…·: çœŸå€¼è®¡ç®—ä¸ä½æ‰“åŒ…
# ==========================================
def compute_ground_truth(db, qs, k=100):
    """æš´åŠ›è®¡ç®— Top-K çœŸå€¼ (åŸºäº Cosine ç›¸ä¼¼åº¦)"""
    print(f"âš¡ Computing Ground Truth for {len(qs)} queries...")
    # å‡è®¾æ•°æ®å·²å½’ä¸€åŒ–ï¼Œä½¿ç”¨çŸ©é˜µä¹˜æ³•è®¡ç®— Cosine
    scores = torch.mm(qs, db.t())
    _, indices = torch.topk(scores, k=k, largest=True)
    return indices

def pack_secret_output(fp_01_np, plain_model):
    """
    å°† SPU è¾“å‡ºçš„æœªå‹ç¼© 0/1 æŒ‡çº¹æ‰“åŒ…æˆ int64 æ ¼å¼ï¼Œ
    ä»¥ä¾¿ç›´æ¥è°ƒç”¨ plain_model.query_with_fingerprints
    """
    # fp_01_np shape: (Batch, Tables, Bits)
    device = plain_model.device
    fp_tensor = torch.tensor(fp_01_np, dtype=torch.int64, device=device)
    
    packed_fp = []
    bits_per_table = fp_tensor.shape[-1]
    
    # æŒ‰ 64 ä½åˆ†å—æ‰“åŒ…
    for i in range(0, bits_per_table, 64):
        chunk = fp_tensor[:, :, i:i + 64]
        # å¦‚æœä¸è¶³ 64 ä½ï¼Œè¿›è¡Œ Padding
        if chunk.shape[2] < 64: 
            chunk = F.pad(chunk, (0, 64 - chunk.shape[2]))
        
        # è°ƒç”¨ plain_model çš„åº•å±‚æ‰“åŒ…å‡½æ•°
        # è¾“å‡º shape: (Batch, Tables)
        packed_chunk = plain_model._pack_bits(chunk)
        packed_fp.append(packed_chunk.unsqueeze(-1))
    
    # æ‹¼æ¥ chunks: (Batch, Tables, Num_Chunks)
    return torch.cat(packed_fp, dim=-1)

# ==========================================
# 2. æµ‹è¯•ç¯å¢ƒ
# ==========================================
@pytest.fixture(scope="module")
def sf_setup():
    sf.shutdown()
    sf.init(['alice', 'bob'], address='local')
    alice = sf.PYU('alice')
    bob = sf.PYU('bob')
    
    cluster_def = sf.utils.testing.cluster_def(
        ['alice', 'bob'],
        runtime_config={
            'protocol': sf.utils.testing.spu_pb2.SEMI2K,
            'field': sf.utils.testing.spu_pb2.FM64,
            'enable_pphlo_profile': False
        }
    )
    spu = sf.SPU(cluster_def)
    yield alice, bob, spu
    sf.shutdown()

class TestAccuracyAndPerformance:
    
    @pytest.fixture(scope="class")
    def dataset(self):
        """åŠ è½½æ•°æ®å¹¶è®¡ç®—çœŸå€¼"""
        DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
        loader = GISTDataLoader()
        # åŠ è½½è¾ƒå¤šæ•°æ®ä»¥ä¿è¯ Recall è®¡ç®—çš„ç»Ÿè®¡æ„ä¹‰
        db, qs = loader.load_data(device=DEVICE, train_limit=10000, test_limit=100)
        
        # è®¡ç®—çœŸå€¼ (Top-100)
        gt_indices = compute_ground_truth(db, qs, k=100)
        
        return {
            "db": db, 
            "qs": qs, 
            "gt": gt_indices,
            "device": DEVICE
        }

    @pytest.fixture(scope="class")
    def model_configs(self):
        return [
            # 1. ç”Ÿäº§çº§ (FWHT + PublicPerm) - é¢„æœŸ: é«˜Recall, é«˜QPS
            {
                "name": "ğŸš€ PublicPerm (Prod)",
                "fwht": True, 
                "public_perm": True,
                "tables": 4
            },
            # 2. æ¶ˆèå®éªŒ (No FWHT) - é¢„æœŸ: ä½Recall, é«˜QPS
            {
                "name": "ğŸ§ª No-FWHT (Ablation)",
                "fwht": False, 
                "public_perm": True,
                "tables": 4
            },
            # 3. å…¨éšç§ (SecretPerm) - é¢„æœŸ: é«˜Recall, æä½QPS
            # æ³¨æ„ï¼šè¿™ä¸ªè·‘èµ·æ¥å¾ˆæ…¢ï¼Œä»…ç”¨äºéªŒè¯æ­£ç¡®æ€§
            {
                "name": "ğŸ”’ SecretPerm (Basic)",
                "fwht": True, 
                "public_perm": False,
                "tables": 4
            }
        ]

    def test_recall_and_perf(self, sf_setup, dataset, model_configs):
        alice, bob, spu = sf_setup
        db, qs, gt_indices = dataset['db'], dataset['qs'], dataset['gt']
        device = dataset['device']
        
        BITS = 2048
        TOP_K = 100
        
        print("\n" + "="*110)
        print(f"ğŸ“Š FULL BENCHMARK: Recall@{TOP_K} & QPS")
        print("="*110)
        print(f"{'Model Name':<25} | {'Recall':<8} | {'Latency(s)':<10} | {'QPS':<8} | {'Build(s)':<8}")
        print("-" * 110)
        
        for cfg in model_configs:
            # 1. å‡†å¤‡æ˜æ–‡æ¨¡å‹ (ä½œä¸ºå‚æ•°æºå’Œæœç´¢å¼•æ“)
            # å¿…é¡»ç”¨çœŸå®æ•°æ®è®­ç»ƒï¼Œå¦åˆ™ Recall æ— æ³•è®¡ç®—
            plain_model = UnifiedLSHRetriever(
                input_dim=960, 
                total_bits=BITS, 
                num_tables=cfg['tables'], 
                projection_type='hadamard',
                device=device
            )
            # è®­ç»ƒæ˜æ–‡æ¨¡å‹ (æ„å»º DB ç´¢å¼•)
            plain_model.train(db)
            
            # 2. å®ä¾‹åŒ–ç§˜å¯†æ¨¡å‹
            secret_model = UnifiedSecretHadamardRetriever(
                spu, plain_model, alice, bob,
                num_tables=cfg['tables'],
                use_fwht=cfg['fwht'],
                use_public_perm=cfg['public_perm']
            )
            
            # 3. Build é˜¶æ®µè®¡æ—¶
            t_build = secret_model.build_secret()
            
            # 4. Query é˜¶æ®µ (æ€§èƒ½ + å¬å›)
            # ä½¿ç”¨å…¨éƒ¨æµ‹è¯•æŸ¥è¯¢ (100æ¡)
            qs_np = qs.cpu().numpy()
            
            try:
                # åªæœ‰ SecretPerm æ¨¡å¼ä¸‹ï¼Œä¸ºäº†é˜²è¶…æ—¶ï¼Œæˆ‘ä»¬åªæµ‹å°‘é‡æ•°æ®
                if not cfg['public_perm']:
                    qs_subset = qs_np[:10]
                    gt_subset = gt_indices[:10]
                    bs = 10
                else:
                    qs_subset = qs_np
                    gt_subset = gt_indices
                    bs = len(qs_np)

                # --- æ ¸å¿ƒè®¡æ—¶ ---
                fp_01, t_query = secret_model.query_secret(qs_subset)
                # ----------------
                
                # 5. åå¤„ç†: è®¡ç®— Recall
                # a. æ‰“åŒ…æŒ‡çº¹ (0/1 -> int64)
                q_fp_packed = pack_secret_output(fp_01, plain_model)
                
                # b. åœ¨æ˜æ–‡åº“ä¸­æ£€ç´¢
                # query_with_fingerprints è¿”å› (Batch, K) çš„ç´¢å¼•
                _, pred_indices = plain_model.query_with_fingerprints(q_fp_packed, k=TOP_K)
                
                # c. è®¡ç®—äº¤é›† (Recall)
                hits = 0
                for i in range(bs):
                    gt_set = set(gt_subset[i].tolist())
                    pred_set = set(pred_indices[i].tolist())
                    hits += len(gt_set & pred_set)
                
                recall = hits / (bs * TOP_K)
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                latency = t_query / bs
                qps = bs / t_query
                
                print(f"{cfg['name']:<25} | {recall:.2%}   | {latency:.4f}     | {qps:.2f}     | {t_build:.4f}")

            except Exception as e:
                print(f"{cfg['name']:<25} | ERROR: {str(e)[:30]}...")

    print("-" * 110)
    print("ğŸ’¡ é¢„æœŸç»“æœè§£è¯»:")
    print("1. [Prod] å’Œ [SecretPerm] çš„ Recall åº”è¯¥éå¸¸æ¥è¿‘ (ä¾‹å¦‚ >50%)ï¼Œä¸” QPS å·®è·å·¨å¤§ã€‚")
    print("2. [No-FWHT] çš„ Recall åº”è¯¥æ˜¾è‘—ä½äºå‰ä¸¤è€… (ä¾‹å¦‚ <10%)ï¼Œè¯æ˜ FWHT å¯¹å‡†ç¡®ç‡è‡³å…³é‡è¦ã€‚")

if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s", "--tb=short"])